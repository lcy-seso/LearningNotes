# My Notes

- [Optimizing RNN performance](Optimizing_RNN_performance/Optimizing_RNN_performance.pdf)
- [QRCNN](./Quasi-Recurrent_neural_network/Quasi-Recurrent_neural_network.pdf)
- [SRU](./Training_RNNs_as_Fast_as_CNNs/Training_RNNs_as_Fast_as_CNNs.pdf)
- [JANET](The_Unreasonable_Effectiveness_of_the_Forget_Gate/The_Unreasonable_Effectiveness_of_the_Forget_Gate.pdf)
- [ClockworkRNN](A_Clockwork_RNN.md)

# Reading List

1. [Fast-Slow Recurrent Neural Networks](https://arxiv.org/abs/1705.08639)
1. [Dilated Recurrent Neural Networks](https://arxiv.org/abs/1710.02224) (NIPS 2017)
    - codes: https://github.com/code-terminator/DilatedRNN
1. [Grid Long Short Term Memory](https://arxiv.org/abs/1507.01526)
1. [Hierarchical Multiscale Recurrent Neural Networks](https://arxiv.org/abs/1609.01704)
1. [Zoneout Regularizing RNNs by Randomly Preserving Hidden Activations](https://arxiv.org/abs/1606.01305)
1. [Training recurrent networks online without backtracking](https://arxiv.org/abs/1507.07680)
1. [Recent Advances in Recurrent Neural Networks](https://arxiv.org/abs/1801.01078)
1. [Gated Feedback Recurrent Neural Networks](https://arxiv.org/abs/1502.02367)
1. [Phased LSTM: accelerating recurrent network training for long or event-based sequences](https://papers.nips.cc/paper/6310-phased-lstm-accelerating-recurrent-network-training-for-long-or-event-based-sequences.pdf)
