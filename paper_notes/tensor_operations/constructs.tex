\section{Looping and conditional branching constructs} \label{section:loop}

Looping constructs integrate legality preconditions in the construct's semantics. Consturcts that indicate parallel patterns do not need additionally dependence analysis.

\begin{tabular}{|c|c|c|c|}
\hline
&TensorShape&Tensor&TensorArray\\
\hline
foreach&\checkmark&\text{\sffamily X}&\checkmark\\
\hline
parallel\_foreach&\text{\sffamily X}&\checkmark(elementwise)&\checkmark\\
\hline
scan&\text{\sffamily X}&\checkmark&\checkmark\\
\hline
zip&\text{\sffamily X}&\text{\sffamily X}&\checkmark\\
\hline
reduce&\text{\sffamily X}&\checkmark&\checkmark\\
\hline
filter&\text{\sffamily X}&\checkmark&\checkmark\\
\hline
broadcast&\text{\sffamily X}&\checkmark&\checkmark\\
\hline
apply\_along\_axis&\text{\sffamily X}&\checkmark&\text{\sffamily X}\\
\hline
\end{tabular}

\subsection{\textbf{\textit{parallel\_foreach}}}

explict parallel looping.

\begin{lstlisting}[language=Python]
parallel_for(func:callable, X:Iterative, **kwargs) -> Iterative # parallel for
\end{lstlisting}

\begin{itemize}
  \item iteration domain: $0 \le i \le \text{len}(X) - 1$
  \item access function: $i \rightarrow X[i]$
  \item shape function is defined when input X is a Tensor array, otherwise (a case is iterating over a index set) None.
 \begin{itemize}
   \item Suppose shape function of func is $S(\text{func}) = \Gamma(S(X))$;
   \item Then $S(\text{foreach}) = (\text{len}(X)) + S(\text{func})$.
 \end{itemize}
 \item computation: $\textbf{parallel\_foreach}$ implies parallel execution of $\text{apply}(\text{func}, \textbf{X}[i], \text{**kwargs})$.
\end{itemize}

\subsection{\textbf{\textit{reduce}}}

\subsection{\textbf{\textit{fold}}}

\subsection{\textbf{\textit{scan}}}

\subsection{\textbf{\textit{broadcast}}}

\begin{lstlisting}[language=Python]
broadcast(func:callable, X:Tensor, Y:Tensor) -> Tensor
\end{lstlisting}

$\mathbf{X}$ is the bigger Tensor, $\mathbf{Y}$ is the smaller tensor.

\subsection{\textbf{\textit{zip}}}

\subsection{\textbf{\textit{filter}}}

\subsection{\textbf{\textit{apply\_along\_axis}}:a combination of gather, scatter and parallel\_foreach}

\begin{lstlisting}[language=Python]
apply_along_axis(func:callable, dim:int, X:Tensor, **kwargs) -> Tensor
\end{lstlisting}

\begin{enumerate}
  \item shape function:
  \begin{itemize}
    \item Suppose shape function of func is: $S(\text{func}) = \Gamma(x)$ which returns a tuple contains only 1 element;
    \item Then, $S(\text{apply\_along\_axis}) = \text{replace}(S(\mathbf{X}), \text{dim}, S(\text{func}))$.
  \end{itemize}

  \item computation
  \begin{equation*}
    \begin{aligned}
      \mathbf{Y}^{S(\text{apply\_along\_axis})} = \textbf{parallel\_foreach}& (i, \text{index} \quad \textbf{in} \quad \text{cartesian\_product}(\text{del}(S(\mathbf{Y}), \text{dim})) \\
      & \text{indices} = \textbf{parallel\_foreach}(i \rightarrow \text{insert}(\text{indices}, \text{dim}, i), \text{arange}(\text{size}(\mathbf{Y}, \text{dim}))) \\
      & \mathbf{Y}_0^{\text{size}(S(\mathbf{Y}), \text{dim})} = \textbf{gather}(\mathbf{Y}, \text{indices}) \\
      & \mathbf{Y}_1^{\text{size}(S(\mathbf{Y}), \text{dim})} = \textbf{apply}(\textbf{func}, \text{args}..., \mathbf{Y}_0^{\text{size}(S(\mathbf{Y}, \text{dim})}) \\
      & \mathbf{Y}_2^{\text{size}(S(\mathbf{Y}), \text{dim})} = \textbf{scatter}(\mathbf{Y}, \text{indices})
    \end{aligned}
  \end{equation*}
\end{enumerate}

\subsection{\textbf{\textit{sortby}}}
