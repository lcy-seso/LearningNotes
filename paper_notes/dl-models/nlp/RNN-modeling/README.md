# My Notes

- [Optimizing RNN performance](Optimizing_RNN_performance/Optimizing_RNN_performance.pdf)
- [QRCNN](Quasi-Recurrent_neural_network/Quasi-Recurrent_neural_network.pdf)
- [SRU](Training_RNNs_as_Fast_as_CNNs/Training_RNNs_as_Fast_as_CNNs.pdf)
- [JANET](The_Unreasonable_Effectiveness_of_the_Forget_Gate/The_Unreasonable_Effectiveness_of_the_Forget_Gate.pdf)
- [ClockworkRNN](CW-RNN/A_Clockwork_RNN.pdf)
- [ON-LSTM](ON-LSTM/ON-LSTM.pdf)
- [HM-LSTM](HM-LSTM/Hierarchical_multiscale_RNN.pdf)
- [GridLSTM](GridLSTM/GridLSTM.pdf)

# Reading List

## RNN Variants

- [ ] [Fast-Slow Recurrent Neural Networks](https://arxiv.org/abs/1705.08639)
- [x] [Dilated Recurrent Neural Networks](https://arxiv.org/abs/1710.02224) (NIPS 2017)
    - codes: https://github.com/code-terminator/DilatedRNN
- [x] [Grid Long Short Term Memory](https://arxiv.org/abs/1507.01526)
- [x] [A Clockwork RNN](https://arxiv.org/abs/1402.3511)
- [x] [Hierarchical Multiscale Recurrent Neural Networks](https://arxiv.org/abs/1609.01704)
- [ ] [Zoneout Regularizing RNNs by Randomly Preserving Hidden Activations](https://arxiv.org/abs/1606.01305)
- [ ] [Recent Advances in Recurrent NMulti-Dimensional Recurrent Neural Networkseural Networks](https://arxiv.org/abs/1801.01078)
- [ ] [Gated Feedback Recurrent Neural Networks](https://arxiv.org/abs/1502.02367)
- [ ] [Phased LSTM: accelerating recurrent network training for long or event-based sequences](https://papers.nips.cc/paper/6310-phased-lstm-accelerating-recurrent-network-training-for-long-or-event-based-sequences.pdf)
- [x] [Multi-dimensional recurrent neural networks](https://arxiv.org/pdf/0705.2011.pdf)
- [x] [Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks](https://openreview.net/pdf?id=B1l6qiR5F7)
- [ ] [Efficient Neural Audio Synthesis](https://arxiv.org/abs/1802.08435)

## Training RNN

- [ ] [A Primal-Dual Method for Training Recurrent Neural Networks Constrained by the Echo-State Property](https://arxiv.org/pdf/1311.6091.pdf)
- [ ] [Training recurrent networks online without backtracking](https://arxiv.org/abs/1507.07680)
- [ ] [Memory-Efficient Backpropagation Through Time](https://arxiv.org/abs/1606.03401)
- [ ] [Training Deep Nets with Sublinear Memory Cost](https://arxiv.org/abs/1604.06174)
